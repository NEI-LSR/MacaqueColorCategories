
\paragraph{Computation of bias} To assess the bias in responses for each cue, we computed the distribution of responses on trials where the monkey made an incorrect choice.
For each completed trial, we calculated the error as the angular difference between the correct option and the chosen option.  
For each cue, we computed the number of times the monkey selected each incorrect choice, normalized by the number of times each choice color was available as a choice option for all completed trials of the given cue (this was approximately uniformly distributed).

We then fit a Gaussian with a variable floor ($a \cdot exp(-(((x-b)^2)/(2c^2)))+d$) to the error distribution for each cue. 
This fit was weighted by the number of times each choice color was an option for the given cue across all completed trials (as before, this was approximately uniformly distributed). 
Bias was taken as the difference between the cue and the peak of the corresponding Gaussian, for each cue color. These values were then smoothed (with a circular moving average filter of 5 cues) since our primary interest was in the broader structure of the bias distribution, and this is shown as the black lines in \autoref{fig:BiasCurves}.

Attractor points (thought to indicate color category centers) occur where the bias curve crosses the zero line from positive to negative (going counter-clockwise).
At these points, there is zero bias, and hues on either side provoke choices that are biased inwards towards this point.
Correspondingly, repeller points occur where the bias curve crosses the zero line from \emph{negative to positive} (again, going counter-clockwise).
At these points there is also zero bias, but hues either side of this point are biased \emph{away} from this point.

\paragraph{Confidence intervals}
%To find the 95\% confidence intervals for the locations of the category centers, we performed 1000 bootstraps on all completed trials. For each bootstrapped sample, we found the bias values for each cue color, smoothed the bias curve, and found the category center locations for each bootstrapped dataset. To find the category center locations for the full data set and their confidence interval, we found the category boundaries and segmented all bootstrapped category centers that fell between two consecutive category boundaries. For each of these segments, we found the circular mean and circular standard deviation of all category crossings that fell within these boundaries. 

%\begin{figure}
%\includesvg[inkscapelatex=false, width=\textwidth]{../../Figures/F2_DataAnalysis_v2.svg}
%\caption{\textbf{Task performance.}
Performance as a function of trial difficulty, quantified as the closeness of the chromatically closest incorrect choice.
%\emph{A.} For one animal, with five example choice sets below for trials where the cue was cue \#28 (correct choice highlighted by dashed line here, not visible to animal).
%\emph{B.} For all animals.
%} 
%\label{fig:TaskPerformance}
%\end{figure}

\begin{figure}
\includesvg[inkscapelatex=false, width=\textwidth]{../../Figures/working/Poster_components/BiasCalculation copy.svg}
\caption{Analysis and Hypotheses.} 
\label{fig:BiasCalculation}
\end{figure}

\paragraph{Learning Rates}

We applied a reinforcement-learning (RL) framework to assess how learning rates varied for each of the 64 colors used during the 4-AFC version of the task. For each animal, we used a Bayesian Adaptive Direct Search algorithm to optimize the learning rate and inverse temperature for every color.
The expected values were updated on each trial based on the following equation:
$$value_i,j(t+1) = value_i,j(t)+p_k*(r(t)-value_i,j(t))$$
where $v_i,j$ is the expected value for selecting option i given cue j, r is a binary value indicating reward feedback for the current trial t, and $p_k$ is the fitted feedback-dependent learning rate parameter for color $k$.

We then passed these value estimates through the softmax function to generate choice probability estimates as follows:
$$d_i,j(t) = exp(beta_k * v_i,j) / sum_x(exp(beta_k(x) * v_i,j(x))): $$
where $d$ is the choice probability, which estimates the certainty of the monkey in selecting the correct choice, and $beta_k$ represents the fitted inverse temperature parameter, which estimates the peak performance for each color k.

Using the choice probability estimate, we computed the negative log likelihood using the following equation:
$$ll = ll â€“ log(d_i,j(t))$$
Where $d_i,j(t)$ represents the choice probability for the correct cue-option combination for each trial $t$.

Comparison of learning rates
The optimal learning rates for each color were plotted in DKL color space, using standard Psychtoolbox methods in MATLAB. Using a Fourier analysis, we then fit the learning rate data in polar DKL color space and determined the statistical significance of any peaks in frequency based on the power spectrum. 